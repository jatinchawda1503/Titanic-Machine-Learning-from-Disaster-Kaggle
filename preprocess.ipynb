{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score ,classification_report ,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    title_list = [\n",
    "                    'Mr', 'Mrs', 'Miss', 'Rev', 'Ms', 'Dr', 'Lady', 'Master', 'Don', 'Mme', \n",
    "                    'Major', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess', 'Jonkheer'\n",
    "                ]\n",
    "    title_mapping = {\n",
    "                        'Mr': ('male', 18, np.inf),\n",
    "                        'Mrs': ('female', 18, np.inf),\n",
    "                        'Miss': ('female', 0, 18),\n",
    "                        'Master': ('male', 0, 18),\n",
    "                        'Rev': ('male', 18, np.inf),\n",
    "                        'Ms': ('female', 18, np.inf),\n",
    "                        'Dr': ('male', 18, np.inf),\n",
    "                        'Dr': ('female', 18, np.inf),\n",
    "                        'Lady': ('female', 18, np.inf),\n",
    "                        'Don': ('male', 18, np.inf),\n",
    "                        'Mme': ('female', 18, np.inf),\n",
    "                        'Major': ('male', 18, np.inf),\n",
    "                        'Sir': ('male', 18, np.inf),\n",
    "                        'Mlle': ('female', 18, np.inf),\n",
    "                        'Col': ('male', 18, np.inf),\n",
    "                        'Capt': ('male', 18, np.inf),\n",
    "                        'Countess': ('female', 18, np.inf),\n",
    "                        'Jonkheer': ('male', 18, np.inf)\n",
    "                    }\n",
    "    INPUT_COLS = ['Sex', 'Pclass','AgeGroup', 'FarePerPerson', 'CabinLetter','FamilyCategory']\n",
    "    TARGET_COL = ['Survived']\n",
    "    CAT_COLS = ['Sex', 'Pclass','AgeGroup', 'CabinLetter','FamilyCategory']\n",
    "    NUM_COLS = ['FarePerPerson']\n",
    "    TEST_SIZE = 0.25\n",
    "    RANDOM_STATE = 42\n",
    "    LBL_ENC = LabelEncoder()\n",
    "    OHE_ENC = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    SCALER = StandardScaler()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tiles_from_names(df):\n",
    "    df['FamilyName'] = df['Name'].apply(lambda x: x.split(',')[0])\n",
    "    df['FirstName'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[1].strip())\n",
    "    df['MappedTitle'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "    return df\n",
    "\n",
    "def map_title(row):\n",
    "    if pd.isnull(row['Age']):\n",
    "        mapped_title = row['MappedTitle']\n",
    "        sex = row['Sex']\n",
    "        for title, (title_sex, min_age, max_age) in CONFIG.title_mapping.items():\n",
    "            if title == 'Dr':\n",
    "                if sex in ['male', 'female'] and mapped_title == 'Dr':\n",
    "                    mapped_title = 'Mr' if sex == 'male' else 'Mrs'\n",
    "                    break\n",
    "            elif title_sex == sex and min_age <= row['Age'] <= max_age:\n",
    "                mapped_title = title\n",
    "                break\n",
    "    else:\n",
    "        sex = row['Sex']\n",
    "        age = row['Age']\n",
    "        for title, (title_sex, min_age, max_age) in CONFIG.title_mapping.items():\n",
    "            if title == 'Dr':\n",
    "                if sex in ['male', 'female'] and min_age <= age <= max_age:\n",
    "                    mapped_title = 'Mr' if sex == 'male' else 'Mrs'\n",
    "                    break\n",
    "            elif title_sex == sex and min_age <= age <= max_age:\n",
    "                mapped_title = title\n",
    "                break\n",
    "    return mapped_title\n",
    "\n",
    "def group_age(title):\n",
    "    if title == \"Mr\" or  title == \"Mr\":\n",
    "        return \"Adult\"\n",
    "    else:\n",
    "        return \"Children\"\n",
    "\n",
    "def fill_age_null_values(df):\n",
    "    df.loc[(df['AgeGroup'] == 'Children') & (df['Age'].isnull()), 'Age'] = float(round(df[df['AgeGroup'] == 'Children']['Age'].median()))\n",
    "    df.loc[(df['AgeGroup'] == 'Adult') & (df['Age'].isnull()), 'Age'] = float(round(df[df['AgeGroup'] == 'Adult']['Age'].median()))\n",
    "    df.drop('MappedTitle', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def handle_age_outliers_for_age(df, age_group):\n",
    "    mask = df['AgeGroup'] == age_group\n",
    "    \n",
    "    q1 = df.loc[mask, 'Age'].quantile(0.25)\n",
    "    q3 = df.loc[mask, 'Age'].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    \n",
    "    df.loc[mask & (df['Age'] < lower_bound), 'Age'] = lower_bound\n",
    "    df.loc[mask & (df['Age'] > upper_bound), 'Age'] = upper_bound\n",
    "    return df\n",
    "\n",
    "def update_family_counts(row, df):\n",
    "    family_name = row['FamilyName']\n",
    "    ticket = row['Ticket']\n",
    "    num_children = df[(df['FamilyName'] == family_name) & (df['Title'].isin(['Miss', 'Master'])) | (df['Ticket'] == ticket) & (df['Title'].isin(['Miss', 'Master']))].shape[0]\n",
    "    num_adults = df[(df['FamilyName'] == family_name) & (df['Title'].isin(['Mr', 'Mrs'])) | (df['Ticket'] == ticket) & (df['Title'].isin(['Mr', 'Mrs']))].shape[0]\n",
    "    row['SibSp'] = num_children\n",
    "    row['Parch'] = num_adults\n",
    "    row['FamilySize'] = num_children + num_adults \n",
    "    return row\n",
    "\n",
    "def categorize_family_size(size):\n",
    "    if size == 1:\n",
    "        return \"Alone\"\n",
    "    elif 1 <= size <= 3:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Large\"\n",
    "    \n",
    "    \n",
    "def create_ticket_to_fare_mapping(df):\n",
    "    duplicate_tickets = df[df['Fare'] != 0].groupby('Ticket')['Fare'].max()\n",
    "    ticket_to_fare = duplicate_tickets.to_dict()\n",
    "    return ticket_to_fare\n",
    "\n",
    "def fill_fare(row, ticket_to_fare ,df):\n",
    "    if row['Fare'] == 0:\n",
    "        if row['Ticket'] in ticket_to_fare:\n",
    "            return ticket_to_fare[row['Ticket']]\n",
    "        elif row['Pclass'] == 1:\n",
    "            return df[df['Pclass'] == 1]['Fare'].mode().iloc[0]\n",
    "        elif row['Pclass'] == 2:\n",
    "            return df[df['Pclass'] == 2]['Fare'].mode().iloc[0]\n",
    "        elif row['Pclass'] == 3:\n",
    "            return df[df['Pclass'] == 3]['Fare'].mode().iloc[0]\n",
    "    elif pd.isnull(row['Fare']):\n",
    "        return df[df['Pclass'] == row['Pclass']]['Fare'].mode().iloc[0]\n",
    "    return row['Fare']\n",
    "\n",
    "def fare_per_person(df):\n",
    "    ticket_counts = df['Ticket'].value_counts()\n",
    "    df['FarePerPerson'] = df['Fare'] / ticket_counts[df['Ticket']].values\n",
    "    return df\n",
    "\n",
    "def outliers_using_iqr_fare(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3-q1\n",
    "    lower_limit = q1 - 1.5*iqr\n",
    "    upper_limit = q3 + 1.5*iqr\n",
    "    df[col] = np.where(df[col] > upper_limit, upper_limit, df[col])\n",
    "    df[col] = np.where(df[col] < lower_limit, lower_limit, df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cabin(row,df):\n",
    "    if row['Cabin'] == 'Unknown' and row['Pclass'] in [1, 2, 3]:\n",
    "        class_condition = row['Pclass']\n",
    "        fare = row['Fare']\n",
    "        duplicate_tickets = df[(df['Ticket'] == row['Ticket']) & (df['Cabin'] != 'Unknown')]['Cabin']\n",
    "        family_members_cabins = df[(df['FamilyName'] == row['FamilyName']) & (df['Cabin'] != 'Unknown')]['Cabin']\n",
    "        if duplicate_tickets.any():\n",
    "            return duplicate_tickets.iloc[0]\n",
    "        \n",
    "        elif family_members_cabins.any():\n",
    "            return family_members_cabins.iloc[0]\n",
    "        else:\n",
    "            if class_condition == 1:\n",
    "                if fare <= 55:\n",
    "                    return 'C123'\n",
    "                elif (55 < fare) & (fare <= 75):\n",
    "                    return np.random.choice(['B22','C2','E44'])\n",
    "                elif (75 < fare) & (fare <= 91):\n",
    "                    return np.random.choice(['C78','C83','E67'])\n",
    "                else:\n",
    "                    return np.random.choice(['B58 B60','C22 C26','C23 C25 C27','C65','C68'])\n",
    "            elif class_condition == 2:\n",
    "                if fare > 13:\n",
    "                    return 'D'\n",
    "                else:\n",
    "                    return 'F2'\n",
    "            elif class_condition == 3:\n",
    "                return 'G6'\n",
    "        \n",
    "    return row['Cabin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_with_one_hot_encoder(data, features):\n",
    "    fitting_encoder = CONFIG.OHE_ENC.fit(data[features]).transform(data[features])\n",
    "    col_names = CONFIG.OHE_ENC.get_feature_names_out(input_features=features)\n",
    "    encoder_df = pd.DataFrame(fitting_encoder, columns=col_names,\n",
    "                              index=data.index)\n",
    "    data = data.join(encoder_df)\n",
    "    data = data.drop(features, axis=1)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def encoder_with_transform(data, features):\n",
    "    fitting_encoder = CONFIG.OHE_ENC.transform(data[features])\n",
    "    col_names = CONFIG.OHE_ENC.get_feature_names_out(input_features=features)\n",
    "    encoder_df = pd.DataFrame(fitting_encoder,\n",
    "                              columns=col_names,\n",
    "                              index=data.index)\n",
    "    data = data.join(encoder_df)\n",
    "    data = data.drop(features, axis=1)\n",
    "    return data\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['FamilyName'] = train_df['Name'].apply(lambda x: x.split(',')[0])\n",
    "train_df['FirstName'] = train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[1].strip())\n",
    "train_df['MappedTitle'] = train_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# Apply the map_title function to create 'Title' column\n",
    "train_df['Title'] = train_df.apply(map_title, axis=1)   \n",
    "train_df['AgeGroup'] = train_df['Title'].apply(lambda x: group_age(x))\n",
    "\n",
    "train_df = fill_age_null_values(train_df)\n",
    "\n",
    "train_df = train_df.apply(lambda row: update_family_counts(row, train_df), axis=1)\n",
    "train_df['FamilyCategory'] = train_df['FamilySize'].apply(categorize_family_size)\n",
    "\n",
    "train_df['Cabin'] = train_df['Cabin'].fillna('Unknown')\n",
    "train_df['CabinLetter'] = train_df['Cabin'].apply(lambda x: str(x)[0])\n",
    "\n",
    "# for pclass in [1, 2, 3]:\n",
    "#     #survived_cabin = train_df[(train_df['Pclass'] == pclass) & (train_df['Survived'] == 1)]['Cabin'].unique()\n",
    "#     #died_cabin = train_df[(train_df['Pclass'] == pclass) & (train_df['Survived'] == 0)]['Cabin'].unique()\n",
    "#     train_df['Cabin'] = train_df.apply(lambda x: fill_cabin(x, train_df), axis=1)\n",
    "train_df['Cabin'] = train_df.apply(lambda x: fill_cabin(x, train_df), axis=1)\n",
    "train_df['CabinLetter'] = train_df['Cabin'].apply(lambda cabin: cabin[0] if cabin != 'Unknown' else 'Unknown')\n",
    "\n",
    "\n",
    "\n",
    "train_df['Embarked'].replace(np.nan,'S',inplace=True)\n",
    "\n",
    "train_df = handle_age_outliers_for_age(train_df, 'Adult')\n",
    "train_df = handle_age_outliers_for_age(train_df, 'Children')\n",
    "\n",
    "ticket_to_fare_mapping = create_ticket_to_fare_mapping(train_df)\n",
    "train_df['Fare'] = train_df.apply(lambda row: fill_fare(row, ticket_to_fare_mapping, train_df), axis=1)\n",
    "train_df = fare_per_person(train_df)\n",
    "\n",
    "train_df = outliers_using_iqr_fare(train_df, 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['FamilyName'] = test_df['Name'].apply(lambda x: x.split(',')[0])\n",
    "test_df['FirstName'] = test_df['Name'].apply(lambda x: x.split(',')[1].split('.')[1].strip())\n",
    "test_df['MappedTitle'] = test_df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "\n",
    "test_df['Title'] = test_df.apply(map_title, axis=1)   \n",
    "test_df['AgeGroup'] = test_df['Title'].apply(lambda x: group_age(x))\n",
    "\n",
    "test_df = fill_age_null_values(test_df)\n",
    "\n",
    "test_df = test_df.apply(lambda row: update_family_counts(row, test_df), axis=1)\n",
    "test_df['FamilyCategory'] = test_df['FamilySize'].apply(categorize_family_size)\n",
    "\n",
    "test_df['Cabin'] = test_df['Cabin'].fillna('Unknown')\n",
    "test_df['CabinLetter'] = test_df['Cabin'].apply(lambda x: str(x)[0])\n",
    "\n",
    "\n",
    "test_df['Cabin'] = test_df.apply(lambda x: fill_cabin(x, test_df), axis=1)\n",
    "test_df['CabinLetter'] = test_df['Cabin'].apply(lambda cabin: cabin[0] if cabin != 'Unknown' else 'Unknown')\n",
    "\n",
    "\n",
    "test_df['Embarked'].replace(np.nan,'S',inplace=True)\n",
    "\n",
    "test_df = handle_age_outliers_for_age(test_df, 'Adult')\n",
    "test_df = handle_age_outliers_for_age(test_df, 'Children')\n",
    "\n",
    "ticket_to_fare_mapping_test = create_ticket_to_fare_mapping(test_df)\n",
    "test_df['Fare'] = test_df.apply(lambda row: fill_fare(row, ticket_to_fare_mapping_test, test_df), axis=1)\n",
    "test_df = fare_per_person(test_df)\n",
    "\n",
    "test_df = outliers_using_iqr_fare(test_df, 'Fare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[CONFIG.INPUT_COLS]\n",
    "y = train_df[CONFIG.TARGET_COL]\n",
    "\n",
    "X_test_df = test_df[CONFIG.INPUT_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=CONFIG.TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jatin\\AppData\\Local\\Temp\\ipykernel_18532\\2030152804.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test_df[col] = CONFIG.SCALER.transform(X_test_df[col].values.reshape(-1,1))\n",
      "c:\\Users\\jatin\\.conda\\envs\\titanic\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# for col in CONFIG.CAT_COLS:    \n",
    "#     CONFIG.LBL_ENC.fit(list(X_train[col].values)) \n",
    "#     X_train[col] = CONFIG.LBL_ENC.transform(list(X_train[col].values))\n",
    "#     X_test[col] = CONFIG.LBL_ENC.transform(list(X_test[col].values))\n",
    "\n",
    "    \n",
    "for col in CONFIG.NUM_COLS:\n",
    "    X_train[col] = CONFIG.SCALER.fit(X_train[col].values.reshape(-1,1)).transform(X_train[col].values.reshape(-1,1))\n",
    "    X_test[col] = CONFIG.SCALER.transform(X_test[col].values.reshape(-1,1))\n",
    "    X_test_df[col] = CONFIG.SCALER.transform(X_test_df[col].values.reshape(-1,1))\n",
    "\n",
    "X_train = encoding_with_one_hot_encoder(X_train, CONFIG.CAT_COLS)\n",
    "X_test = encoder_with_transform(X_test, CONFIG.CAT_COLS)\n",
    "X_test_df = encoder_with_transform(X_test_df, CONFIG.CAT_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jatin\\.conda\\envs\\titanic\\Lib\\site-packages\\sklearn\\base.py:1151: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85       122\n",
      "           1       0.89      0.67      0.77       101\n",
      "\n",
      "    accuracy                           0.82       223\n",
      "   macro avg       0.84      0.80      0.81       223\n",
      "weighted avg       0.83      0.82      0.81       223\n",
      "\n",
      "[[114   8]\n",
      " [ 33  68]]\n",
      "0.8161434977578476\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=8, min_samples_leaf=16, min_samples_split=2, max_features='sqrt' )\n",
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "y_test_pred = rf.predict(X_test_df)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": y_test_pred\n",
    "    })\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jatin\\.conda\\envs\\titanic\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.87       122\n",
      "           1       0.87      0.78      0.82       101\n",
      "\n",
      "    accuracy                           0.85       223\n",
      "   macro avg       0.85      0.84      0.84       223\n",
      "weighted avg       0.85      0.85      0.85       223\n",
      "\n",
      "[[110  12]\n",
      " [ 22  79]]\n",
      "0.8475336322869955\n"
     ]
    }
   ],
   "source": [
    "gb_trees = GradientBoostingClassifier( n_estimators=100, random_state=0, learning_rate=0.1, max_depth=6, min_samples_leaf=8, min_samples_split=8, subsample=0.8)\n",
    "gb_trees.fit(X_train, y_train)\n",
    "gb_pred = gb_trees.predict(X_test)\n",
    "print(classification_report(y_test, gb_pred))\n",
    "print(confusion_matrix(y_test, gb_pred))\n",
    "print(accuracy_score(y_test, gb_pred))\n",
    "\n",
    "\n",
    "gb_test_pred = gb_trees.predict(X_test_df)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": gb_test_pred\n",
    "    })\n",
    "submission.to_csv('submission_gb.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
